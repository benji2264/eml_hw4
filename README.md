# eml_hw4

NB: The ```modeling_llama.py``` script is meant to replace the one from the HF library. The main difference is that it saves the attention weights in order to plot the attention maps later with ```visualize_attn.ipynb```
